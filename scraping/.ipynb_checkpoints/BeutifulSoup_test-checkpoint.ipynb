{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests)\n",
      "  Using cached https://files.pythonhosted.org/packages/b4/40/a9837291310ee1ccc242ceb6ebfd9eb21539649f193a7c8c86ba15b98539/urllib3-1.25.7-py2.py3-none-any.whl\n",
      "Collecting idna<2.9,>=2.5 (from requests)\n",
      "  Using cached https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl\n",
      "Installing collected packages: certifi, chardet, urllib3, idna, requests\n",
      "Successfully installed certifi-2019.11.28 chardet-3.0.4 idna-2.8 requests-2.22.0 urllib3-1.25.7\n",
      "Collecting beautifulsoup4\n",
      "  Downloading https://files.pythonhosted.org/packages/cb/a1/c698cf319e9cfed6b17376281bd0efc6bfc8465698f54170ef60a485ab5d/beautifulsoup4-4.8.2-py3-none-any.whl (106kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 3.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>=1.2 (from beautifulsoup4)\n",
      "  Using cached https://files.pythonhosted.org/packages/81/94/03c0f04471fc245d08d0a99f7946ac228ca98da4fa75796c507f61e688c2/soupsieve-1.9.5-py2.py3-none-any.whl\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.8.2 soupsieve-1.9.5\n",
      "Collecting lxml\n",
      "  Using cached https://files.pythonhosted.org/packages/45/e4/dab6984433261722901ca0c3708b3e15fc94fac4b83b1eae9dfed52134e3/lxml-4.4.2-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-4.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install requests\n",
    "!pip3 install beautifulsoup4\n",
    "!pip3 install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import certifi\n",
    "import urllib.request\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "# urlopen error [SSL: CERTIFICATE_VERIFY_FAILED]を回避\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANONICOカラーストライプ\n",
      "https://www.zerbino.info/blog/2020/01/29059.html\n",
      "新年も茶色からはじまります。笑\n",
      "https://www.zerbino.info/blog/2020/01/29029.html\n",
      "色とりどりのシャツ生地が待っています。\n",
      "https://www.zerbino.info/blog/2020/01/29040.html\n",
      "今ほしいストール\n",
      "https://www.zerbino.info/blog/2020/01/28964.html\n",
      "イタリアンなカラー\n",
      "https://www.zerbino.info/blog/2019/12/28913.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.zerbino.info/blog/page/1\"\n",
    "html = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "entry_lists = soup.find_all(\"h2\", class_=\"entry-title\")\n",
    "for entry in entry_lists:\n",
    "    print(entry.find(\"a\").string)\n",
    "    print(entry.find(\"a\").get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "max_page = 5\n",
    "entry_list = []\n",
    "url_list = []\n",
    "\n",
    "for lPage in range(1, max_page + 1):\n",
    "    url = \"https://www.zerbino.info/blog/page/\" + str(lPage)\n",
    "    soup = BeautifulSoup(urllib.request.urlopen(url), \"html.parser\")\n",
    "    entry_list.extend(soup.find_all(\"h2\", class_=\"entry-title\"))\n",
    "    for entry in entry_list:\n",
    "        \n",
    "\n",
    "print(len(entry_list))\n",
    "\n",
    "# リスト同士の結合\n",
    "#entry_list_1.extend(entry_list_2)\n",
    "#print(entry_list_1)\n",
    "#len(entry_list_1)\n",
    "# 重複を除外する\n",
    "#set1=set(list1)\n",
    "#print(set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "新年も茶色からはじまります。笑\n",
      "\n",
      "2020年1月6日\n",
      "\n",
      "【オーダースーツ ZERBINO銀座店 Blog】\n",
      " \n",
      " \n",
      "こんにちは！\n",
      " \n",
      "ZERBINO銀座店の松田です。\n",
      " \n",
      "本日のご紹介はこちら\n",
      "\n",
      "【Fabric】\n",
      "LORO PIANA  – ロロピアーナ –\n",
      " \n",
      "【Order Suit】\n",
      "Custom Line ￥79,000(+tax)\n",
      "Luxury Line ￥119,000(+tax)\n",
      "※ベストは別途となります。\n",
      " \n",
      "イタリア、ロロピアーナの\n",
      "ブラウンチェックでダブルベスト付き\n",
      "スーツをオーダーいただきました。\n",
      "\n",
      "グレーとダークブラウンが混じった色合いで、\n",
      "薄紫系のペンが柔らかく洒落た雰囲気を出していて\n",
      "とても素敵です。\n",
      " \n",
      "ロロピアーナならではの\n",
      "深みと立体感のある生地の質と色柄は\n",
      "衿付きベストだとより映えますね。\n",
      "\n",
      "Vゾーンが浅くなるので、\n",
      "かなり強めのペイズリータイを合わせていますが、\n",
      "スタイルとの調和がとれるので良いと思います。\n",
      " \n",
      "深い大人の色気があり、\n",
      "しっかり存在感のあるこの生地を\n",
      "検討される方はぜひベストもお考えください。\n",
      "ここまでの色柄は\n",
      "スタイルもしっかりされるのが正解です。\n",
      " \n",
      " \n",
      " \n",
      "■営業情報\n",
      "月～土　11：00-20：00\n",
      "日のみ　11：00-18：30\n",
      "※連休の場合は日曜も通常営業で最終日が18：30までとなります。\n",
      " \n",
      "■銀座店専用LINEアカウント\n",
      "お問い合わせなどお気軽にご連絡ください。\n",
      "パソコンでの対応となりますので\n",
      "返答にお時間をいただく場合がございます。\n",
      "お急ぎの場合はお電話いただければ対応いたします。\n",
      "ID : @qfo7587s\n",
      "\n",
      " \n",
      "■ZERBINO銀座店へのアクセス\n",
      "銀座駅編はこちらをご覧ください。\n",
      " \n",
      "■ZERBINO TOP\n",
      "URL: https://www.zerbino.info/\n",
      " \n",
      "■ZERBINO Gallery\n",
      "URL: https://www.zerbino.info/gallery/suit\n",
      " \n",
      "■ZERBINO Item & Price\n",
      "URL：https://www.zerbino.info/item/\n",
      " \n",
      "■Instagram\n",
      "URL：https://www.instagram.com/zerbino_fundress/\n",
      "共有:クリックして Twitter で共有 (新しいウィンドウで開きます)Facebook で共有するにはクリックしてください (新しいウィンドウで開きます)Click to share on Google+ (新しいウィンドウで開きます)いいね:いいね 読み込み中...\n",
      "\n",
      "関連\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# entry_lists[n]のnで記事番号を選ぶ\n",
    "one_blog = BeautifulSoup(urllib.request.urlopen(entry_lists[1].find(\"a\").get(\"href\")), \"html.parser\")\n",
    "print(one_blog.find(\"h2\", class_=\"entry-title\").text)\n",
    "print(one_blog.find(\"span\", class_=\"entry-date\").text)\n",
    "print(one_blog.find(\"div\", class_=\"entry-body\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# クラス作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import certifi\n",
    "import urllib.request\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup \n",
    "import ssl # urlopen error [SSL: CERTIFICATE_VERIFY_FAILED]を回避\n",
    "\n",
    "class single_entry:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.title_tag = \"\"\n",
    "        self.title_class = \"\"\n",
    "        self.date_tag = \"\"\n",
    "        self.date_class = \"\"\n",
    "        self.body_tag = \"\"\n",
    "        self.body_class = \"\"\n",
    "        self.__isReady = False\n",
    "        self.__title = \"\"\n",
    "        self.__date = \"\"\n",
    "        self.__body = \"\"\n",
    "    \n",
    "    def __GetReady(self):\n",
    "        soup = BeautifulSoup(urllib.request.urlopen(self.url), \"html.parser\")\n",
    "        self.__title = soup.find(self.title_tag, class_=self.title_class).text\n",
    "        self.__date = soup.find(self.date_tag, class_=self.date_class).text\n",
    "        self.__body = soup.find(self.body_tag, class_=self.body_class).text\n",
    "        self.__isReady = True\n",
    "\n",
    "    def GetTitle(self):\n",
    "        if self.__isReady == False:\n",
    "            self.__GetReady()\n",
    "        return self.__title\n",
    "    \n",
    "    def GetDate(self):\n",
    "        if self.__isReady == False:\n",
    "            self.__GetReady()\n",
    "        return self.__date\n",
    "    \n",
    "    def GetBody(self):\n",
    "        if self.__isReady == False:\n",
    "            self.__GetReady()\n",
    "        return self.__body\n",
    "    \n",
    "    def GetAll(self):\n",
    "        if self.__isReady == False:\n",
    "            self.__GetReady()\n",
    "        return self.__title, self.__date, self.__body\n",
    "        \n",
    "    \n",
    "# CANONICOカラーストライプ\n",
    "# https://www.zerbino.info/blog/2020/01/29059.html\n",
    "# find(\"h2\", class_=\"entry-title\").text\n",
    "# print(single_entry.find(\"span\", class_=\"entry-date\").text)\n",
    "# print(single_entry.find(\"div\", class_=\"entry-body\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CANONICOカラーストライプ\n",
      "\n",
      "2020年1月7日\n",
      "\n",
      "【ZERBINO新宿　大坂】\n",
      " \n",
      "ZERBINO新宿店の大坂です。\n",
      " \n",
      "最近、気になっている生地があります。\n",
      "近年カラーストライプがきになる所ですが\n",
      "ご紹介するのは英国の本格的なカラーストライプではなく\n",
      "イタリアCANONICO社のカラーストライプです。\n",
      "\n",
      "【Fabric】CANONICO　94-3295\n",
      "custom　Line￥69,000+tax\n",
      "Luxury　Line　￥109,000+tax\n",
      " \n",
      "色は、光沢のあるネイビーベースの生地に薄くブルーのストライプが入っています。\n",
      "一見上品で光沢のあるネイビー無地ですが、よく見るとカラーストライプがでてきます。\n",
      "（画像では伝わりにくいですが、美しい光沢感です）\n",
      "無地でもなく、シャドーストライプでもない生地感は上質そのもの。\n",
      " \n",
      "ビジネスでしっかり上質に見せたい方には有効的かもしれません。\n",
      "ネイビースーツにいつもと違う変化をつけたい方は、必見です。\n",
      " \n",
      "新宿店　　　大坂\n",
      " \n",
      "■新宿店専用LINEアカウント\n",
      "お問い合わせやなど直接承ります。\n",
      "基本的にご来店いただいた順番に対応させていただきますが、\n",
      "ご予約いただければなるべくスタッフを空けておくよう\n",
      "手配させていただきます。\n",
      "パソコンでの対応となりますので返答にお時間をいただく場合がございます。\n",
      "お急ぎの場合はお電話いただければ対応いたします。\n",
      "登録ID ： @253hxeso\n",
      "※友だち検索で上記のIDを入力するか、\n",
      "QRコード読み込みで登録お願い致します。\n",
      "http://nav.cx/fULCXy7(こちらのリンクで友達追加が出来ます。)\n",
      "\n",
      "\n",
      "\n",
      "■営業情報\n",
      "月～土　11：00-20：00\n",
      "日のみ　11：00-18：30\n",
      "※連休の場合は日曜も通常営業で最終日が18：30までとなります。\n",
      " \n",
      "■ZERBINO新宿店へのアクセス\n",
      "新宿店へのアクセスはこちらをご覧ください。\n",
      "■ZERBINO TOP\n",
      "URL: https://www.zerbino.info/\n",
      "■ZERBINO Gallery\n",
      "\n",
      "\n",
      "共有:クリックして Twitter で共有 (新しいウィンドウで開きます)Facebook で共有するにはクリックしてください (新しいウィンドウで開きます)Click to share on Google+ (新しいウィンドウで開きます)いいね:いいね 読み込み中...\n",
      "\n",
      "関連\n",
      " \n"
     ]
    }
   ],
   "source": [
    "entry_zerbino = blog_entry(\"https://www.zerbino.info/blog/2020/01/29059.html\")\n",
    "entry_zerbino.title_tag = \"h2\"\n",
    "entry_zerbino.title_class = \"entry-title\"\n",
    "entry_zerbino.date_tag = \"span\"\n",
    "entry_zerbino.date_class = \"entry-date\"\n",
    "entry_zerbino.body_tag = \"div\"\n",
    "entry_zerbino.body_class = \"entry-body\"\n",
    "\n",
    "print(entry_zerbino.GetTitle())\n",
    "print(entry_zerbino.GetDate())\n",
    "print(entry_zerbino.GetBody())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "## pagenationを調べる\n",
    "## pageごとに全エントリを抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>【ミニコラム】誰も教えてくれない、股下の最適な長さ | ブログ | 東京のオーダースーツ【ZERBINO】ゼルヴィーノ</title>\n",
      "title\n",
      "【ミニコラム】誰も教えてくれない、股下の最適な長さ | ブログ | 東京のオーダースーツ【ZERBINO】ゼルヴィーノ\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.zerbino.info/blog/2019/12/28657.html\"\n",
    "html = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "#soup.find_all(True)\n",
    "\n",
    "print(soup.title)\n",
    "print(soup.title.name)   #title\n",
    "print(soup.title.string) #Remrinのpython攻略日記\n",
    "\n",
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神記事\n",
    "https://qiita.com/itkr/items/513318a9b5b92bd56185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2 class=\"entry-title\">\n",
      "<a href=\"https://www.zerbino.info/blog/2019/12/28788.html\">安定のブラウン推しです。</a>\n",
      "</h2>, <h2 class=\"entry-title\">\n",
      "<a href=\"https://www.zerbino.info/blog/2019/12/28701.html\">私物紹介　カシミヤマフラー</a>\n",
      "</h2>, <h2 class=\"entry-title\">\n",
      "<a href=\"https://www.zerbino.info/blog/2019/12/28728.html\">存在感のあるコートです。</a>\n",
      "</h2>, <h2 class=\"entry-title\">\n",
      "<a href=\"https://www.zerbino.info/blog/2019/12/28780.html\">Cesare Gatti/チェザーレ ガッティのカシミアマフラー</a>\n",
      "</h2>, <h2 class=\"entry-title\">\n",
      "<a href=\"https://www.zerbino.info/blog/2019/12/28746.html\">フォーマルにベルベットはいかがですか？</a>\n",
      "</h2>]\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.zerbino.info/blog/page/2\"\n",
    "html = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "#soup.find_all(True)\n",
    "\n",
    "# 例えば<a href=\"/link\" class=\"link\">のように\n",
    "# classがlinkでhrefが/linkのaタグをすべて取得するには\n",
    "# soup.find_all(\"a\", class_=\"link\", href=\"/link\")\n",
    "#print(soup.find(\"div\", class_=\"entry-header\"))\n",
    "print(soup.find_all(\"h2\", class_=\"entry-title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "安定のブラウン推しです。\n",
      "https://www.zerbino.info/blog/2019/12/28788.html\n"
     ]
    }
   ],
   "source": [
    "entry_lists = soup.find_all(\"h2\", class_=\"entry-title\")\n",
    "print(entry_lists[0].find(\"a\").string)\n",
    "print(entry_lists[0].find(\"a\").get(\"href\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ちゃうねん\n",
    "\n",
    "https://www.geekfeed.co.jp/geekblog/blog_update_bot#142931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_update(url):\n",
    "    html = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    # 記事のリスト要素を取得\n",
    "    posts = soup.find(class_=\"blog_list\").find_all(\"li\", class_=\"clearfix\")\n",
    "    articles = []\n",
    " \n",
    "    for post in posts:\n",
    "        title = post.h3.a.string\n",
    "        url = post.h3.a['href']\n",
    "        author = post.find(class_=\"author\").span.string\n",
    "        # 日付をチェックするために記事の中へ\n",
    "        article_html = urllib.request.urlopen(url)\n",
    "        soup = BeautifulSoup(article_html, \"html.parser\")\n",
    "        post_date_str = soup.find('meta', attrs={'property': 'article:published_time'}).get('content')\n",
    "        #post_date = datetime.datetime.strptime(post_date_str, \"%Y-%m-%dT%H:%M:%S%fZ\")\n",
    "        #post_date = pytz.utc.localize(post_date).astimezone(pytz.timezone(\"Asia/Tokyo\"))\n",
    "        # 日付チェック\n",
    "        #if post_date < target_date:\n",
    "        #    break\n",
    " \n",
    "        article_dict = {\n",
    "            \"title\": title,\n",
    "            \"url\": url,\n",
    "            \"author\": author\n",
    "        }\n",
    "        articles.append(article_dict)\n",
    " \n",
    "    return articles\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ちょっと違う\n",
    "http://be-07.hatenablog.com/entry/2016/12/23/012055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entry_list(html):\n",
    "    url_list = [html]\n",
    "    while True:\n",
    "        html = requests.get(html).content\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "        next_page = soup.find(\"a\", {\"class\", \"skinSimpleBtn pagingNext\"})\n",
    "        if isinstance(next_page, type(None)):\n",
    "            print(\"finish\")\n",
    "            return url_list\n",
    "        else:\n",
    "            url_list.append(next_page[\"href\"])\n",
    "            html = next_page[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.zerbino.info/blog/page/\"\n",
    "# 記事のリスト要素を取得\n",
    "posts = get_entry_list(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.zerbino.info/blog/page/']\n"
     ]
    }
   ],
   "source": [
    "print(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 近いけど違う\n",
    "https://yukituna.com/1684/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-8eaf0168e62a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.zerbino.info/blog/2019/12\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetLinks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-8eaf0168e62a>\u001b[0m in \u001b[0;36mgetLinks\u001b[0;34m(articleUrl)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticleUrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbsObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbsObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"sitemap_list\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.zerbino.info/blog/2019/12\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def getLinks(articleUrl):\n",
    "    html = urlopen(articleUrl)\n",
    "    bsObj = BeautifulSoup(html, \"html.parser\")\n",
    "    return bsObj.find(\"ul\", {\"id\": \"sitemap_list\"}).find_all(\"a\")\n",
    "\n",
    "url = \"https://www.zerbino.info/blog/2019/12\"\n",
    "links = getLinks(url)\n",
    "for link in links:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scrapyを使うしかない？\n",
    "https://www.sejuku.net/blog/69383"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

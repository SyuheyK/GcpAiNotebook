{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl\n",
      "Collecting idna<2.9,>=2.5 (from requests)\n",
      "  Using cached https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests)\n",
      "  Using cached https://files.pythonhosted.org/packages/b4/40/a9837291310ee1ccc242ceb6ebfd9eb21539649f193a7c8c86ba15b98539/urllib3-1.25.7-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl\n",
      "Installing collected packages: idna, chardet, urllib3, certifi, requests\n",
      "Successfully installed certifi-2019.11.28 chardet-3.0.4 idna-2.8 requests-2.22.0 urllib3-1.25.7\n",
      "Collecting beautifulsoup4\n",
      "  Using cached https://files.pythonhosted.org/packages/cb/a1/c698cf319e9cfed6b17376281bd0efc6bfc8465698f54170ef60a485ab5d/beautifulsoup4-4.8.2-py3-none-any.whl\n",
      "Collecting soupsieve>=1.2 (from beautifulsoup4)\n",
      "  Using cached https://files.pythonhosted.org/packages/81/94/03c0f04471fc245d08d0a99f7946ac228ca98da4fa75796c507f61e688c2/soupsieve-1.9.5-py2.py3-none-any.whl\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.8.2 soupsieve-1.9.5\n",
      "Collecting lxml\n",
      "  Using cached https://files.pythonhosted.org/packages/45/e4/dab6984433261722901ca0c3708b3e15fc94fac4b83b1eae9dfed52134e3/lxml-4.4.2-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-4.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install requests\n",
    "!pip3 install beautifulsoup4\n",
    "!pip3 install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import certifi\n",
    "import urllib.request\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "# urlopen error [SSL: CERTIFICATE_VERIFY_FAILED]を回避\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class single_entry:\n",
    "    def __init__(self, inUrl):\n",
    "        self.title_tag = \"\"\n",
    "        self.title_class = \"\"\n",
    "        self.date_tag = \"\"\n",
    "        self.date_class = \"\"\n",
    "        self.body_tag = \"\"\n",
    "        self.body_class = \"\"\n",
    "        self.__isReady = False\n",
    "        self.__url = inUrl\n",
    "        self.__title = \"\"\n",
    "        self.__date = \"\"\n",
    "        self.__body = \"\"\n",
    "    \n",
    "    def SetURL(self, inUrl):\n",
    "        self.__url = inUrl\n",
    "        self.__isReady = False        \n",
    "    \n",
    "    def __GetReady(self):\n",
    "        soup = BeautifulSoup(urllib.request.urlopen(self.__url), \"html.parser\")\n",
    "        self.__title = soup.find(self.title_tag, class_=self.title_class).text\n",
    "        self.__date = soup.find(self.date_tag, class_=self.date_class).text\n",
    "        self.__body = soup.find(self.body_tag, class_=self.body_class).text\n",
    "        self.__isReady = True\n",
    "    \n",
    "    def GetTitle(self):\n",
    "        if self.__isReady == False:\n",
    "            self.__GetReady()\n",
    "        return self.__title\n",
    "    \n",
    "    def GetDate(self):\n",
    "        if self.__isReady == False:\n",
    "            self.__GetReady()\n",
    "        return self.__date\n",
    "    \n",
    "    def GetBody(self):\n",
    "        if self.__isReady == False:\n",
    "            self.__GetReady()\n",
    "        return self.__body\n",
    "    \n",
    "    def GetAll(self):\n",
    "        if self.__isReady == False:\n",
    "            self.__GetReady()\n",
    "        return self.__title, self.__date, self.__body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "https://www.zerbino.info/blog/2020/01/29059.html\n",
      "https://www.zerbino.info/blog/2020/01/29029.html\n"
     ]
    }
   ],
   "source": [
    "max_page = 5\n",
    "entry_list = []\n",
    "url_list = []\n",
    "\n",
    "for lPage in range(1, max_page + 1):\n",
    "    url = \"https://www.zerbino.info/blog/page/\" + str(lPage)\n",
    "    soup = BeautifulSoup(urllib.request.urlopen(url), \"html.parser\")\n",
    "    entry_list.extend(soup.find_all(\"h2\", class_=\"entry-title\"))\n",
    "\n",
    "for entry in entry_list:\n",
    "    url_list.append(entry.find(\"a\").get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_zerbino = single_entry(\"\")\n",
    "entry_zerbino.title_tag = \"h2\"\n",
    "entry_zerbino.title_class = \"entry-title\"\n",
    "entry_zerbino.date_tag = \"span\"\n",
    "entry_zerbino.date_class = \"entry-date\"\n",
    "entry_zerbino.body_tag = \"div\"\n",
    "entry_zerbino.body_class = \"entry-body\"\n",
    "\n",
    "title_list = []\n",
    "date_list = []\n",
    "body_list = []\n",
    "\n",
    "for lUrl in url_list:\n",
    "    entry_zerbino.SetURL(lUrl)\n",
    "    ltitle, ldate, lbody = entry_zerbino.GetAll()\n",
    "    title_list.append(ltitle)\n",
    "    date_list.append(ldate)\n",
    "    body_list.append(lbody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
